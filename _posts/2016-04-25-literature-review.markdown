---
layout: post
title:  "Literature Review on Artificial Intelligence Ethics"
date:   2016-04-25 21:52:45
description: My literature review assignment
categories:
- blog
---
&nbsp

The artificial intelligence is a hot-debated topic since this concept was came up decades ago. Not only the scientific progress that this field has approached during the past decades, but also a bunch of the great literatures such as movies and fictions published. Humans always dedicate for the power of the AI, while there are so many unsure and dangerous elements in this field, which made people are also fear about the power behind it. Recently, a very hot news brought our sights back to the artificial intelligence, which is the chess game held between the “Alphago” and Lee Seldo, who are the AI invented by google and one of the best human chess player in the world responsively. Alphago ended up won this game by a huge margin. This was a good opportunity to show how big progress scientists have achieved during past years, but at same time, there are lots of questioning voices raised up. Some people are more concerned about the safety of human future for their worries like one day artificial intelligence overpassed the power of human. So in this literature review, I am going to focus on the study of how to balance the AI ethics and the huge power behind it, and the results of related researches.

In the research “AI Ethics: Science Fiction Meets Technological Reality” (Daniel Zeng), it demonstrated that lots of great work contributed not only by scientific fields, but also in philosophy and literature. Big company and government gathered groups of researcher to develop ethics frameworks. The author claim that a legal and safe AI ethics were basically established rather than the immature AI system in old ages. He discussed 6 major thread concerning AI ethics. The first thread discussed about the most popular question that is whether AI will someday destroy human. He quoted from some great computer scientist such as Bill Gates to convey that AI will very likely terminate human age, worse still, AI is able to build themselves more and more powerful until eventually break the control by human. The second thread focused on the society conflicts such as the influence of automation on economy and employment. The research pointed out that the advantage is quite obvious such as the enhanced quality of goods. However, at same time the structure of employment in human world was seriously affected and will come up unstable elements in human society. The third thread questioned that whether human world legal system is also available to be applied to AI, and the answer is negative. It discussed some complicated scenario, especially the case of driverless car which is a hot project nowadays. The rest of three thread focused on the relationship between human and robots and rights for both. The research told us some companies used robots as weapon to against human, while sometimes robots are in the weaken position. And also the challenging relationship and ethics issue between human and humanoid robots was discussed. The author concluded that AI ethics is becoming increasingly close to us rather than a purely philosophical topic. People started to build more rules on the classic three laws of robotics. And the further enhancement of AI needs more development of AI ethic to support. This study is very up-to-date, we can see it from the case of driverless car. But limitation for this research is that it lacks of specific data to support his argument. For example, the second thread talked about the decreasing employment in human world. If a table or paragraph of data is provided, it would be more visual to readers. And also when the author talked about the robotic weapon in the fourth thread, he did not mention how bad the effect was and what people reacted after this event happened. The author claimed that “It’s safe to say that a new era of AI is coming”, but from the major thread he listed, some of them still have no solution yet, which conflicted with what he said at beginning of the paper.

In the research “Rise of Concerns about AI: Reflections and Directions” (Thomas G. Dietterich and Eric J. Horvitz) studied about the benefit and arising problems come with the AI, and the directions to the future. It first listed benefits that people have gained from the development of AI from the daily life to the academic field such as neurobiology and psychology. This research was mostly focus on the potential risk of the AI and the elements that can cause the AI loss its control. They summed up five classes of risk: bugs, cybersecurity, the “Sorcerer’s Apprentice”, shared autonomy and socioeconomic impacts. The research concluded that much more effort should be devoted if we want to use the power of the AI and the study should be open to public since sometimes it goes beyond pure science. There are certain limitation for studies in some of the categories and some conflicts that against their own conclusion. For example, the research pointed out that “computer scientists must continue to investigate and address concerns about the possibility of the loss of control of machine”. And also the end of the research claimed that deeper study is needed to understand AI. However, author also claimed “the risk of AI is  very small and far in the future” in the paragraph before where he talked about the first set of risks. Besides,  the second class -- cybersecurity is more about a human influent element. This is not a typical case when study on the potential risk of AI compares to  the problem that AI itself comes up,  such as the “intelligence explosion” problem.

Unlike the most common voices such as limiting the power of the AI, the research paper “Safety Engineering for Artificial General Intelligence” (Roman Yampolskiy and Joshua Fox) proposed a new science of safety engineering for intelligent artificial agents based on maximizing the human value. Their study showed that Near-human AIs have the ability to upgrade themselves, which will cause the intelligence explosion for they can build higher level AI and recursively continue. The research mentioned the “three classic rules”, but the author believed that no such rules can capture every possible situation. Moreover, there are no rules can constrain AI when they are smarter than human. Even the cooperation will not work when a single intelligence is far more powerful than the other one. The author concluded that human morality was not needed to apply on the super intelligence but safety engineering did. The safety engineering is the subject that focus on preserving the essential humanity of their values, and prevent AIs to change themselves worse and recursively improve themselves. The author also warned that even though the power of AI should not be restricted while the research on it should be. Because the experiment will put human in danger without a safe design in advance. It also talked about robots’ rights. In conclusion, the author believed that AI safety needs to make progress rapidly both theoretically and practically. More experiments should be held under a safe design ahead. The research came up some really fantastic opinions, however, some of them conflicted with each other. It emphasis to make AI recursively improve the safety value that human gave to them while it is hard to predict and control once AI vastly overpass human. Besides, when the author talked about the rights of robots, he said that AI should not have same rights of human, but it will be no longer determined by human anymore when AI upgrades itself to superintelligence.

Next is a journal “Risks of General Artificial Intelligence” (Müller and Vincent C)  that basically summarized the topic of papers came from a conference on the ‘Impacts and Risks of Artificial General Intelligence’ on 10 and 11 December 2012. This journal pointed out that AI is much superior than human, moreover, it is able to improve itself in increasing speed. Two different voice rise up, one believed that the ultraintelligent machine would obey the human and tell us how to make them under control, while the other voice believed that they were a significant risk which could affect the existence of human. Some people thought that the AI study should stop if the stakes is about the human extinction, while others believed that for the next decades, human would increasingly rely on the strong AI. In conclusion,  the editor left a series of opening questions while he still believe that we are on the right track and the cautious progress is better than nothing. But we need to be very careful to the future studies on AI.  There is one claim “One possibility is that ‘the first ultraintelligent machine is the last invention that man need ever make, provided that the machine is docile enough to tell us how to keep it under control”, which has a logic error. Even though, the ultraintelligent machine turn out to be docile to human, it does not mean that AI can satisfy all needs from human. Some certain needs still require human being to create by ourselves.

To sum up, it is not difficult to see the huge progress that human have made in AI field. Meantime, scientists are also studying on the AI ethic to ensure the safety of human’s future. Even though many questions are still hanging on the air, however, terrific ideas comes up continuously and related safe experiments keep undergoing. I believe scientist will attain more achievement over next few decades, however the ethic behind it seems even harder than the technique itself. Let us hope that all human being are well prepared when the ultraintelligent machine really comes out one day.  		


References:

> Zeng, Daniel. "AI Ethics: Science Fiction Meets Technological Reality." IEEE Intelligent Systems 3 (2015): 2. Academic OneFile. Web. 1 Apr. 2016.

> Dietterich, Thomas G., and Eric J. Horvitz. "Rise of concerns about AI: reflections and directions." Communications of the ACM 2015: 38. Academic OneFile. Web. 1 Apr. 2016.

> Yampolskiy, Roman1, roman.yampolskiy@louisville.edu, and Joshua2, joshua.fox@singinst.org Fox. "Safety Engineering For Artificial General Intelligence." Topoi 32.2 (2013): 217-226.Humanities Source. Web. 1 Apr. 2016.

> Müller, Vincent C. "Risks Of General Artificial Intelligence." Journal Of Experimental & Theoretical Artificial Intelligence 26.3 (2014): 297-301. Computer Source. Web. 1 Apr. 2016.
